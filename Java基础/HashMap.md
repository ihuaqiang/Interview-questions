###HashMap的结构和底层原理？

HashMap是我们常用的数据结构，由数组和链表和红黑树构成的数据结构。

当添加元素的时候，会通过哈希值和数组长度计算下标来定位该元素应该put的位置，为了使元素分布均匀会使用高位运算，
取模运算计算出index，然后将该元素添加进去，理想状态下是均匀的添加到数组中，但问题是不可能达到这样的理想状态，
这时候就会产生Hash冲突。
此时就产生了第二种数据结构-链表，冲突的元素会在该元素处以链表的形式保存。

当链表的长度过长时，查询效率会降低，时间复杂度可能达到O(n)级别，而数组的查询时间复杂度仅为O(1)

此时，就引出了第三种数据结构-红黑树，红黑树是一颗接近于平衡的二叉树，其查询复杂度为O(logn),远远比链表的查询效率高。
但是链表长度不到一定的阈值，直接使用红黑树代替链表是不行的，因为红黑树的自身维护代价也是比较高的，每插入一个元素都
可能打破红黑树的平衡性，这就需要每时每刻对红黑树再平衡(左旋，右旋，重新着色)


###HashMap的存取原理？
HashMap在存数据的时候是基于Hash的原理，当调用put(key,value)方法的时候，会先对键key调用key.hashcode()方法，
根据方法返回hashcode来找bucket(哈希桶数组（Node[] table）)的位置来存Node对象。

如果两个 key 的 hashcode 相同,那么他们对应的 bucket 显然也是相同的,这个时候就会产生所谓的碰撞.每个 bucket 索引对应一个链表,
这个时候系统就会找到对应的链表,并在链表的尾部加上这个 Node 对象

当调用 get(key)的时候,会调用 key 的 hashcode方法获得hashcode.根据 hashcode 获取响应的 bucket.由于一个 bucket 对应的链表中
可能存有多个 Node,这时候会调用 key 的 equals 方法来找到对应的 Node,最会返回值.


###JDK1.7和 JDK1.8HashMap 的区别
数组和链表改成了数组和链表和红黑树
链表的插入方式由头插法改成了尾插法,就是插入时,如果数组位置上已经有元素,1.7 将元素放到数组中,原始节点作为新节点的后继节点,
1.8 遍历链表,将元素放置到链表的最后
扩容的时候 1.7 需要对原数组中的元素重新 Hash 定位在新元素的位置,1.8 采用更简单的判断逻辑,位置不变或索引加旧容量大小
在插入时，1.7先判断是否需要扩容，再插入，1.8先进行插入，插入完成再判断是否需要扩容；
Java1.8相比1.7做了调整，1.7做了四次移位和四次异或，但明显Java 8觉得扰动做一次就够了，做4次的话，多了可能边际效用也不大，所谓为了效率考虑就改成一次了。





###为啥会线程不安全
因为 1.7 头插法扩容的时候,头插法会使链表发生反转,多线程下会形成环
还会产生数据丢失,数据覆盖的问题
1.8 会产生数据覆盖的问题,在判断 index 为空的位置,A 线程正好挂起了,B 线程开始在 index 的位置写入节点数据,这时 A 线程恢复,执行赋值操作,
此时线程 A 不用再进行 Hash 判断了,问题出现:线程 A会把线程 B 插入的数据覆盖


###默认初始化大小是多少？为啥是这么多？为啥大小都是2的幂？
默认的初始化大小是16的原因是这样的，如果桶初始化数组设置太大，就会浪费内存空间，16是一个折中的大小，既不会像1，2，3那样放几个元素就扩容，也不会像几千万那样造成空间的大量的浪费。
大小都是2的幂是，在计算buckets桶位置的时候，公式为((n-1)&hash),2的幂减去1的数的二进制结尾都是1，与hash值进行运算的，会得到其余数。进行按位与操作，使得结果剩下的值为末尾几位，这样只要保证hash值足够散列就可以了


###HashMap的扩容方式？负载因子是多少？为什是这么多？
加载因子设置为0.75而不是1，是因为设置过大，桶中键值对碰撞的几率就会越大，同一个桶位置可能会存放好几个value值，这样就会增加搜索的时间，性能下降，设置过小也不合适，如果是0.1，那么10个桶，threshold为1，你放两个键值对就要扩容，太浪费空间了。

###HashMap是怎么处理hash碰撞的？
如果key相同，则会替换key对应的内容最最小值，key不相同，则接到后面的链表，如果链表长度到达8且数组的长度大于64时，则将链表转为红黑树，如果数组长度小于64，则是进行扩容